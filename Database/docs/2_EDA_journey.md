> "*Damn, she really leveled up that day.*"

# ğŸ“Š Phase 4: Exploratory Data Analysis (EDA) + CSV Cleanup

## ğŸ”¥ What Was This Phase About?

This was the turning point of the project where raw IPL data turned into clean, structured, and database-ready assets.
It wasnâ€™t just data wranglingâ€”it was **engineering clarity out of chaos**.

We performed:

* Schema-aligned column transformations
* Data type conversions (especially `DATE`)
* Mapping CSV values to database foreign keys
* Drop + Rename operations
* CLI-based `\copy` operations to PostgreSQL tables

---

## ğŸ§¬ Dataset Columns Before Cleaning

### ğŸ Players.csv

```
['ID', 'Name', 'longName', 'battingName', 'fieldingName', 'imgUrl',
 'dob', 'battingStyles', 'longBattingStyles', 'bowlingStyles',
 'longBowlingStyles', 'playingRoles', 'espn_url']
```

### ğŸ¯ Actions Performed

| Step | Transformation                                                                                                        |
| ---- | --------------------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£  | Dropped: `ID`, `battingStyles`, `longBattingStyles`, `bowlingStyles`, `longBowlingStyles`, `playingRoles`, `espn_url` |
| 2ï¸âƒ£  | Renamed: `longName â name`, `Name â display_name`                                                                     |
| 3ï¸âƒ£  | Converted `dob` to proper `datetime.date`                                                                             |
| 4ï¸âƒ£  | Ensured all final fields matched DB schema types                                                                      |
| 5ï¸âƒ£  | Exported clean dataset as `cleaned_players.csv`                                                                       |

âœ… **Schema-Aligned Columns:**

```python
['name', 'batting_name', 'fielding_name', 'img_url', 'dob', 'batting_style', 'bowling_style']
```

---

### ğŸ› ï¸ PostgreSQL Insert Operation (Players)

```sql
\copy Players(name, batting_name, fielding_name, img_url, dob, batting_style, bowling_style)
FROM 'C:/Users/hp/Desktop/IPL/notebooks/EDA/cleaned_players.csv' DELIMITER ',' CSV HEADER;
```

âœ… Result: `COPY 261`
â˜ ï¸ First tried using `COPY`, got permission error
ğŸ§  Learned difference between `COPY` vs `\copy` (server vs client-side)

---

### ğŸ§‘â€ğŸ’» Teams.csv Cleanup

Original columns:

```
['team_name', 'url', 'espn_id']
```

| Step | Transformation                                |
| ---- | --------------------------------------------- |
| ğŸ§¹   | Dropped `espn_id`                             |
| ğŸ”   | Renamed: `team_name â name`, `url â logo_url` |
| ğŸ“¤   | Exported as `cleaned_team.csv`                |

Post-cleaning columns:

```
['name', 'logo_url']
```

**Insert into DB:**

```sql
\copy Teams(name, logo_url) FROM 'C:/Users/hp/Desktop/IPL/notebooks/EDA/cleaned_team.csv' DELIMITER ',' CSV HEADER;
```

âœ… Result: `COPY 19`

---

## ğŸ’ª CLI + DB: First Taste of Raw Power

> "*The first time I saw my data enter the actual database through terminalâ€”no ORM, no GUIâ€”was a different level of rush.*"

* Directly inserted into PostgreSQL using `\copy`
* Validated schema with `\d players`, `\d teams`
* Queried data with `SELECT * FROM players LIMIT 5;`
* Used `\dt` to list tables like a true terminal ninja

---

## âš ï¸ Issues Faced & Fixes

| Issue                                | Fix                                                                       |
| ------------------------------------ | ------------------------------------------------------------------------- |
| `COPY FROM` permission denied        | Used `\copy` from psql shell instead                                      |
| CLI command hanging on `ALTER TABLE` | Discovered `idle in transaction` sessions using `pg_stat_activity`        |
| `KeyError` on mapping                | Realized columns were missing after transformations                       |
| Mapping player names failed          | Detected mismatch: `player_of_match` only had names, not full names       |
| Data type mismatch                   | Fixed float `team_id`s by converting to `Int64` or using `.astype('int')` |

---

## ğŸ§  Key Learnings

* CLI-based DB ops give **precise control**, but come with responsibility
* Mapping values from CSV to DB **requires normalization + alignment**
* **Foreign key dependencies** force you to clean earlier tables first
* Never underestimate the impact of column naming (`name` vs `longName` ğŸ¤¯)
* Hands-on practice >> watching 10 tutorials

---

## ğŸ§‘â€ğŸš€ Personal Reflections

> "This was the phase where I didnâ€™t feel like a student anymoreâ€”I felt like a **developer**."

* Felt the **impact of design choices**
* Faced and solved real-world issues instead of blindly copying
* CLI + Jupyter + SQL = POWER ğŸ’¥

---

## ğŸ“ Files Produced

```
notebooks/EDA/cleaned_players.csv
notebooks/EDA/cleaned_team.csv
```

---